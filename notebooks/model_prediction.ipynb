{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-03T07:58:58.254246Z",
     "start_time": "2026-01-03T07:58:57.867276Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T07:58:58.363960Z",
     "start_time": "2026-01-03T07:58:58.352443Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('./../data/preprocessed_matches.csv')\n",
    "df.head()\n",
    "df = df.rename(columns={'winner': 'winner_label', 'outcome': 'outcome_label'}) if 'winner' in df.columns else df\n",
    "label_map = {'H_or_D': 0, 'A': 1}"
   ],
   "id": "b47c8edae7cd1075",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T07:58:58.538344Z",
     "start_time": "2026-01-03T07:58:58.536616Z"
    }
   },
   "cell_type": "code",
   "source": [
    "features = [\n",
    "    'elo_home_pre', 'elo_away_pre', 'elo_diff_pre',\n",
    "    'home_gf_roll', 'home_ga_roll', 'home_pts_roll',\n",
    "    'away_gf_roll', 'away_ga_roll', 'away_pts_roll',\n",
    "    'rest_days_home', 'rest_days_away', 'rest_days_diff',\n",
    "    'h2h_avg_points_home', 'h2h_avg_points_away'\n",
    "]"
   ],
   "id": "c2f69eb533d001a2",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "80fbef2d4b6de0ef"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T07:45:59.981570Z",
     "start_time": "2026-01-03T07:45:59.976732Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = df[df['season'] != 2015]\n",
    "df['season'].unique()"
   ],
   "id": "92e1cc87ea8af472",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024, 2025])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T07:59:12.153780Z",
     "start_time": "2026-01-03T07:59:10.184671Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login()"
   ],
   "id": "de324b9db9dcd412",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/philipbaumann/Projects/epl-match-outcome-predictor/.venv/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/Users/philipbaumann/Projects/epl-match-outcome-predictor/.venv/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mphilip-baumann\u001B[0m (\u001B[33mphilip-baumann-hslu\u001B[0m) to \u001B[32mhttps://api.wandb.ai\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T19:18:12.511144Z",
     "start_time": "2026-01-03T19:18:12.500953Z"
    }
   },
   "cell_type": "code",
   "source": [
    "features_subsets = [\n",
    "    ['elo_home_pre', 'elo_away_pre', 'elo_diff_pre',\n",
    "     'home_gf_roll', 'home_ga_roll', 'home_pts_roll',\n",
    "     'away_gf_roll', 'away_ga_roll', 'away_pts_roll',\n",
    "     'rest_days_home', 'rest_days_away', 'rest_days_diff',\n",
    "     'h2h_avg_points_home', 'h2h_avg_points_away'],\n",
    "\n",
    "    ['elo_home_pre', 'elo_away_pre', 'elo_diff_pre'],\n",
    "    ['elo_home_pre', 'elo_away_pre', 'elo_diff_pre',\n",
    "     'h2h_avg_points_home', 'h2h_avg_points_away'],\n",
    "    ['elo_home_pre', 'elo_away_pre', 'elo_diff_pre',\n",
    "     'rest_days_home', 'rest_days_away', 'rest_days_diff'],\n",
    "    ['elo_home_pre', 'elo_away_pre', 'elo_diff_pre',\n",
    "     'home_gf_roll', 'home_ga_roll', 'home_pts_roll',\n",
    "     'away_gf_roll', 'away_ga_roll', 'away_pts_roll'],\n",
    "    ['elo_home_pre', 'elo_away_pre', 'elo_diff_pre',\n",
    "     'home_gf_roll', 'home_ga_roll', 'home_pts_roll',\n",
    "     'away_gf_roll', 'away_ga_roll', 'away_pts_roll',\n",
    "     'rest_days_home', 'rest_days_away', 'rest_days_diff'],\n",
    "\n",
    "    ['home_gf_roll', 'home_ga_roll', 'home_pts_roll',\n",
    "     'away_gf_roll', 'away_ga_roll', 'away_pts_roll'],\n",
    "    ['home_gf_roll', 'home_ga_roll', 'home_pts_roll',\n",
    "     'away_gf_roll', 'away_ga_roll', 'away_pts_roll',\n",
    "     'rest_days_home', 'rest_days_away', 'rest_days_diff'],\n",
    "    ['home_gf_roll', 'home_ga_roll', 'home_pts_roll',\n",
    "     'away_gf_roll', 'away_ga_roll', 'away_pts_roll',\n",
    "     'h2h_avg_points_home', 'h2h_avg_points_away'],\n",
    "    ['home_gf_roll', 'home_ga_roll', 'home_pts_roll',\n",
    "     'away_gf_roll', 'away_ga_roll', 'away_pts_roll',\n",
    "     'rest_days_home', 'rest_days_away', 'rest_days_diff',\n",
    "     'h2h_avg_points_home', 'h2h_avg_points_away'],\n",
    "\n",
    "    ['rest_days_home', 'rest_days_away', 'rest_days_diff'],\n",
    "    ['rest_days_home', 'rest_days_away', 'rest_days_diff',\n",
    "     'home_gf_roll', 'home_ga_roll', 'home_pts_roll',\n",
    "     'away_gf_roll', 'away_ga_roll', 'away_pts_roll',\n",
    "     'h2h_avg_points_home', 'h2h_avg_points_away'],\n",
    "    ['rest_days_home', 'rest_days_away', 'rest_days_diff',\n",
    "     'home_gf_roll', 'home_ga_roll', 'home_pts_roll',\n",
    "     'away_gf_roll', 'away_ga_roll', 'away_pts_roll',\n",
    "     'elo_home_pre', 'elo_away_pre', 'elo_diff_pre'\n",
    "     ],\n",
    "    ['h2h_avg_points_home', 'h2h_avg_points_away']\n",
    "]\n",
    "sweep_config = {\n",
    "    \"method\": \"grid\",\n",
    "    \"metric\": {\n",
    "        \"name\": \"logloss\",\n",
    "        \"goal\": \"minimize\"\n",
    "    },\n",
    "    \"parameters\": {\n",
    "        \"n_estimators\": {\"values\": [50, 100, 200, 500]},\n",
    "        \"max_depth\": {\"values\": [None, 50, 100, 200, 500]}\n",
    "    }\n",
    "}"
   ],
   "id": "549662aabc8e57ef",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T07:41:34.334936Z",
     "start_time": "2026-01-03T07:41:33.447956Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score, log_loss, precision_score, recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def train_wrapper(feature_subset):\n",
    "    def train():\n",
    "        seasons = df[\"season\"].unique()\n",
    "        fold_accuracy = []\n",
    "        fold_logloss = []\n",
    "        fold_precision = []\n",
    "        fold_recall = []\n",
    "\n",
    "        run = wandb.init()\n",
    "        config = run.config\n",
    "        run.name = (\n",
    "            f\"rf_\"\n",
    "            f\"n{config.n_estimators}_\"\n",
    "            f\"md{config.max_depth if config.max_depth is not None else 'None'}\"\n",
    "        )\n",
    "\n",
    "        model = RandomForestClassifier(\n",
    "            n_estimators=config.n_estimators,\n",
    "            max_depth=config.max_depth,\n",
    "            random_state=42,\n",
    "            class_weight='balanced',\n",
    "        )\n",
    "\n",
    "        for i in range(1, len(seasons)):\n",
    "            train_seasons = seasons[:i]\n",
    "            test_seasons = [seasons[i]]\n",
    "\n",
    "            train_df = df[df[\"season\"].isin(train_seasons)]\n",
    "            test_df = df[df[\"season\"].isin(test_seasons)]\n",
    "\n",
    "            X_train = train_df[feature_subset]\n",
    "            y_train = train_df['target']\n",
    "            X_test = test_df[feature_subset]\n",
    "            y_test = test_df['target']\n",
    "\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            preds = model.predict(X_test)\n",
    "\n",
    "            prob = model.predict_proba(X_test)\n",
    "            pred_labels = np.argmax(prob, axis=1)\n",
    "\n",
    "            fold_accuracy.append(accuracy_score(y_test, preds))\n",
    "            fold_logloss.append(log_loss(y_test, prob))\n",
    "            fold_precision.append(precision_score(y_test, pred_labels, average='macro'))\n",
    "            fold_recall.append(recall_score(y_test, pred_labels, average='macro'))\n",
    "\n",
    "        wandb.log({\n",
    "            \"accuracy\": np.mean(fold_accuracy),\n",
    "            \"logloss\": np.mean(fold_logloss),\n",
    "            \"precision\": np.mean(fold_precision),\n",
    "            \"recall\": np.mean(fold_recall),\n",
    "        })\n",
    "\n",
    "        wandb.finish()\n",
    "\n",
    "    return train\n",
    "\n"
   ],
   "id": "9cc8a76f06c07c33",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import hashlib\n",
    "\n",
    "tracker = {}\n",
    "\n",
    "for feature in features_subsets:\n",
    "    short = hashlib.sha1(feature.__str__().encode()).hexdigest()[:8]\n",
    "    tracker[short] = feature\n",
    "    sweep_id = wandb.sweep(sweep_config, project=f\"rf-model-7-{short}\")\n",
    "    wandb.agent(sweep_id, function=train_wrapper(feature), count=20)\n"
   ],
   "id": "6852a6dcad2f693f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T17:03:33.590413Z",
     "start_time": "2026-01-02T17:03:33.576997Z"
    }
   },
   "cell_type": "code",
   "source": "tracker[\"37f16e03\"]",
   "id": "ba73a28c35f9f1d4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['elo_home_pre',\n",
       " 'elo_away_pre',\n",
       " 'elo_diff_pre',\n",
       " 'home_gf_roll',\n",
       " 'home_ga_roll',\n",
       " 'home_pts_roll',\n",
       " 'away_gf_roll',\n",
       " 'away_ga_roll',\n",
       " 'away_pts_roll',\n",
       " 'rest_days_home',\n",
       " 'rest_days_away',\n",
       " 'rest_days_diff',\n",
       " 'h2h_avg_points_home',\n",
       " 'h2h_avg_points_away']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T07:43:32.634688Z",
     "start_time": "2026-01-03T07:43:32.631410Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sweep_config = {\n",
    "    \"method\": \"bayes\",   # besser als random für LogLoss\n",
    "    \"metric\": {\n",
    "        \"name\": \"logloss\",\n",
    "        \"goal\": \"minimize\"\n",
    "    },\n",
    "    \"parameters\": {\n",
    "\n",
    "        \"learning_rate\": {\n",
    "            \"distribution\": \"log_uniform_values\",\n",
    "            \"min\": 0.01,\n",
    "            \"max\": 0.1\n",
    "        },\n",
    "\n",
    "        \"num_leaves\": {\n",
    "            \"values\": [15, 31, 63, 127]\n",
    "        },\n",
    "\n",
    "        \"min_data_in_leaf\": {\n",
    "            \"values\": [10, 20, 50, 100]\n",
    "        },\n",
    "\n",
    "        \"feature_fraction\": {\n",
    "            \"values\": [0.7, 0.8, 0.9, 1.0]\n",
    "        },\n",
    "\n",
    "        \"bagging_fraction\": {\n",
    "            \"values\": [0.7, 0.8, 0.9, 1.0]\n",
    "        },\n",
    "\n",
    "        \"bagging_freq\": {\n",
    "            \"values\": [0, 5, 10]\n",
    "        }\n",
    "    }\n",
    "}\n"
   ],
   "id": "86f8736ec4064a7e",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T07:42:14.287949Z",
     "start_time": "2026-01-03T07:42:14.281902Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import lightgbm as lgb\n",
    "def train_wrapper_lightgbm(feature_subset):\n",
    "    def train():\n",
    "        seasons = df[\"season\"].unique()\n",
    "        fold_accuracy = []\n",
    "        fold_logloss = []\n",
    "        fold_precision = []\n",
    "        fold_recall = []\n",
    "\n",
    "        run = wandb.init()\n",
    "        config = run.config\n",
    "        run.name = (\n",
    "            f\"lightgbm_lr-{config.learning_rate}_nl-{config.num_leaves}_mdil-{config.min_data_in_leaf}_fr-{config.feature_fraction}_bfg-{config.bagging_fraction}_bagging_freq-{config.bagging_freq}\"\n",
    "        )\n",
    "\n",
    "        params = {\n",
    "            \"objective\": \"binary\",\n",
    "            \"metric\": \"binary_logloss\",\n",
    "            \"verbosity\": -1,\n",
    "            \"seed\": 42,\n",
    "            \"learning_rate\": config.learning_rate,\n",
    "            \"num_leaves\": config.num_leaves,\n",
    "            \"min_data_in_leaf\": config.min_data_in_leaf,\n",
    "            \"feature_fraction\": config.feature_fraction,\n",
    "            \"bagging_fraction\": config.bagging_fraction,\n",
    "            \"bagging_freq\": config.bagging_freq,\n",
    "        }\n",
    "\n",
    "        for i in range(1, len(seasons)):\n",
    "            train_seasons = seasons[:i]\n",
    "            test_seasons = [seasons[i]]\n",
    "\n",
    "            train_df = df[df[\"season\"].isin(train_seasons)]\n",
    "            test_df = df[df[\"season\"].isin(test_seasons)]\n",
    "\n",
    "            X_train = train_df[feature_subset]\n",
    "            y_train = train_df['target']\n",
    "            X_test = test_df[feature_subset]\n",
    "            y_test = test_df['target']\n",
    "\n",
    "            lgb_tr = lgb.Dataset(X_train, label=y_train)\n",
    "            model = lgb.train(params, lgb_tr, num_boost_round=1000)\n",
    "\n",
    "            preds = model.predict(X_test)\n",
    "            pred_labels = (preds >= 0.5).astype(int)\n",
    "\n",
    "            fold_accuracy.append(accuracy_score(y_test, pred_labels))\n",
    "\n",
    "            fold_logloss.append(log_loss(y_test, preds))\n",
    "\n",
    "            fold_precision.append(precision_score(y_test, pred_labels, average='macro', zero_division=0))\n",
    "\n",
    "            fold_recall.append(recall_score(y_test, pred_labels, average='macro', zero_division=0))\n",
    "\n",
    "\n",
    "        wandb.log({\n",
    "            \"accuracy\": np.mean(fold_accuracy),\n",
    "            \"logloss\": np.mean(fold_logloss),\n",
    "            \"precision\": np.mean(fold_precision),\n",
    "            \"recall\": np.mean(fold_recall),\n",
    "        })\n",
    "\n",
    "        wandb.finish()\n",
    "\n",
    "    return train\n",
    "\n"
   ],
   "id": "dd79c95c3e42e7e1",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import hashlib\n",
    "\n",
    "tracker = {}\n",
    "\n",
    "for feature in features_subsets:\n",
    "    short = hashlib.sha1(feature.__str__().encode()).hexdigest()[:8]\n",
    "    tracker[short] = feature\n",
    "    sweep_id = wandb.sweep(sweep_config, project=f\"lightgbm-model-3-{short}\")\n",
    "    wandb.agent(sweep_id, function=train_wrapper_lightgbm(feature), count=20)"
   ],
   "id": "d2f236696597ac47",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-04T09:35:50.029772Z",
     "start_time": "2026-01-04T09:35:50.024038Z"
    }
   },
   "cell_type": "code",
   "source": "tracker[\"04a61c2b\"]",
   "id": "b473ce889f18cb56",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['elo_home_pre',\n",
       " 'elo_away_pre',\n",
       " 'elo_diff_pre',\n",
       " 'home_gf_roll',\n",
       " 'home_ga_roll',\n",
       " 'home_pts_roll',\n",
       " 'away_gf_roll',\n",
       " 'away_ga_roll',\n",
       " 'away_pts_roll']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T07:59:20.047379Z",
     "start_time": "2026-01-03T07:59:20.044445Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sweep_params = {\n",
    "    \"method\": \"bayes\",   # besser als random für LogLoss\n",
    "    \"metric\": {\n",
    "        \"name\": \"logloss\",\n",
    "        \"goal\": \"minimize\"\n",
    "    },\n",
    "    \"parameters\": {\n",
    "        \"learning_rate\": {\n",
    "            \"distribution\": \"log_uniform_values\",\n",
    "            \"min\": 0.01,\n",
    "            \"max\": 0.2\n",
    "        },\n",
    "\n",
    "        \"n_estimators\": {\n",
    "            \"values\": [100, 200, 400, 800]\n",
    "        },\n",
    "\n",
    "        \"max_depth\": {\n",
    "            \"values\": [3, 4, 5, 6, 8]\n",
    "        },\n",
    "\n",
    "        \"min_child_weight\": {\n",
    "            \"values\": [1, 5, 10, 20]\n",
    "        },\n",
    "\n",
    "        \"subsample\": {\n",
    "            \"values\": [0.6, 0.8, 1.0]\n",
    "        },\n",
    "\n",
    "        \"colsample_bytree\": {\n",
    "            \"values\": [0.6, 0.8, 1.0]\n",
    "        },\n",
    "    }\n",
    "\n",
    "\n",
    "}\n"
   ],
   "id": "6e893da8188a9f99",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T07:59:24.386834Z",
     "start_time": "2026-01-03T07:59:23.555119Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, log_loss, precision_score, recall_score\n",
    "\n",
    "def train_wrapper_xgboost(feature_subset):\n",
    "    def train():\n",
    "        seasons = df[\"season\"].unique()\n",
    "        fold_accuracy = []\n",
    "        fold_logloss = []\n",
    "        fold_precision = []\n",
    "        fold_recall = []\n",
    "\n",
    "        run = wandb.init()\n",
    "        config = run.config\n",
    "        run.name = (\n",
    "            f\"xgbclassifier_lr-{config.learning_rate}_n-{config.n_estimators}md-{config.max_depth}_mcw-{config.min_child_weight}_sub-{config.subsample}_cb-{config.colsample_bytree}\"\n",
    "        )\n",
    "\n",
    "        xgb_model = XGBClassifier(\n",
    "            n_estimators=config.n_estimators,\n",
    "            max_depth=config.max_depth,\n",
    "            learning_rate=config.learning_rate,\n",
    "            subsample=config.subsample,\n",
    "            colsample_bytree=config.colsample_bytree,\n",
    "            random_state=42,\n",
    "            objective=\"binary:logistic\",\n",
    "            eval_metric=\"logloss\"\n",
    "        )\n",
    "\n",
    "        for i in range(1, len(seasons)):\n",
    "            train_seasons = seasons[:i]\n",
    "            test_seasons = [seasons[i]]\n",
    "\n",
    "            train_df = df[df[\"season\"].isin(train_seasons)]\n",
    "            test_df = df[df[\"season\"].isin(test_seasons)]\n",
    "\n",
    "            X_train = train_df[feature_subset]\n",
    "            y_train = train_df['target']\n",
    "            X_test = test_df[feature_subset]\n",
    "            y_test = test_df['target']\n",
    "\n",
    "            # Fit model\n",
    "            xgb_model.fit(X_train, y_train)\n",
    "\n",
    "            # Predict probabilities\n",
    "            prob = xgb_model.predict_proba(X_test)[:, 1]\n",
    "            pred_labels = (prob >= 0.5).astype(int)\n",
    "\n",
    "            fold_accuracy.append(accuracy_score(y_test, pred_labels))\n",
    "\n",
    "            fold_logloss.append(log_loss(y_test, prob))\n",
    "\n",
    "            fold_precision.append(precision_score(y_test, pred_labels, zero_division=0))\n",
    "\n",
    "            fold_recall.append(recall_score(y_test, pred_labels, zero_division=0))\n",
    "\n",
    "\n",
    "        wandb.log({\n",
    "            \"accuracy\": np.mean(fold_accuracy),\n",
    "            \"logloss\": np.mean(fold_logloss),\n",
    "            \"precision\": np.mean(fold_precision),\n",
    "            \"recall\": np.mean(fold_recall),\n",
    "        })\n",
    "\n",
    "        wandb.finish()\n",
    "\n",
    "    return train\n",
    "\n"
   ],
   "id": "4da57bf758cafc44",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T17:54:33.564102Z",
     "start_time": "2026-01-03T17:54:33.561426Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import hashlib\n",
    "\n",
    "tracker = {}\n",
    "\n",
    "for feature in features_subsets:\n",
    "    short = hashlib.sha1(feature.__str__().encode()).hexdigest()[:8]\n",
    "    tracker[short] = feature\n",
    "    #sweep_id = wandb.sweep(sweep_params, project=f\"xgboost-model-3-{short}\")\n",
    "    #wandb.agent(sweep_id, function=train_wrapper_xgboost(feature), count=20)"
   ],
   "id": "6f445f8cf598e1e7",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-04T12:53:46.430728Z",
     "start_time": "2026-01-04T12:53:46.421868Z"
    }
   },
   "cell_type": "code",
   "source": "tracker[\"a1d097d6\"]",
   "id": "4d1bfdbc1b0af5d2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['elo_home_pre', 'elo_away_pre', 'elo_diff_pre']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ea514d53a02055c7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
